{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate branch simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/anaconda/lib/python3.4/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xray\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data from two different sources:\n",
    "\n",
    "1. Monthly-averaged output from `arg_comp` with `PD` emissions\n",
    "2. High-frequency instantaneous output from `aerosol_dists` simulation which branched from **(1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_ROOT_DIR = \"/Volumes/legion_home/CESM_archive/act_aie_aci/\"\n",
    "instant_data = xray.open_dataset(\n",
    "    os.path.join(DATA_ROOT_DIR, \"aerosols\", \"aerosol_dists_PD.sample.nc\"), decode_times=False)\n",
    "average_data = xray.open_mfdataset(\n",
    "    os.path.join(DATA_ROOT_DIR, \"PD\", \"arg_comp\", \"atm\", \"hist\",\n",
    "                 \"arg_comp_PD.cam.h0.*.nc\"), decode_times=False)\n",
    "TIMES_SET = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the same set of variables available in each dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in instant_data.variables:\n",
    "    if not (v in average_data.variables):\n",
    "        print(\"{:>15s} is missing!\".format(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No output means we're good to go! So we can go ahead and subset from the average dataset to reduce the amount of data we have to manipulate. Simultaneously, let's reduce the amount of data that we have to work with in the following ways:\n",
    "\n",
    "- Get rid of the first five years of data from the \"averaged\" case; it's spin-up and not useful. Note that the timestamp of the \"averaged\" data denotes the *end* of the period over which it was averaged, so we should adjust the dates in place first. To facilitate this, the times were not decoded when read in earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting calendar dates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/anaconda/lib/python3.4/site-packages/xarray/conventions.py:779: UserWarning: CF decoding is overwriting dtype\n",
      "  warnings.warn(\"CF decoding is overwriting dtype\")\n"
     ]
    }
   ],
   "source": [
    "## Re-index from year 0 to year 2000, accounting for month offset\n",
    "if not TIMES_SET:\n",
    "    \n",
    "    ## Promote to dataset\n",
    "    average_data_coords = average_data.coords.to_dataset()\n",
    "    instant_data_coords = instant_data.coords.to_dataset()\n",
    "    print(\"setting calendar dates...\")\n",
    "    \n",
    "    average_data_coords.time.values += 2000.*365\n",
    "    instant_data_coords.time.values += 2000.*365\n",
    "    \n",
    "    ## Decode\n",
    "    average_data = xray.decode_cf(average_data)\n",
    "    instant_data = xray.decode_cf(instant_data)\n",
    "    \n",
    "    # AVERAGE DATA\n",
    "    # Shift monthly offsets using Pandas machinery\n",
    "    atimes = average_data.time.to_index()\n",
    "    atimes = atimes.shift(-1, 'MS')\n",
    "    \n",
    "    # INSTANT DATA\n",
    "    # Add constant offset of 9 years to align with last year of average data\n",
    "    itimes = instant_data.time.to_index()\n",
    "    itimes = itimes + np.timedelta64(9, 'Y')\n",
    "    \n",
    "    # Re-assign to original dataset\n",
    "    average_data = average_data.assign_coords(time=atimes)\n",
    "    instant_data = instant_data.assign_coords(time=itimes)\n",
    "    TIMES_SET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Slice off first five years\n",
    "average_data = average_data.sel(time=slice('2006-01', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the global average, annual cycle over the final years of the \"averaged\" case to monthly-aggregate estimates from the \"instantaneous\" case. Use global aerosol loading of **BC**, **OC**, and **SUL** for the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC\n",
      "MBS\n",
      "OC\n",
      "SUL\n",
      "pSUL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/workspace/marc_analysis/marc_analysis/analysis.py:11: UserWarning: Unable to load geopandas/shapely; ocean shape mask not available.\n",
      "  warnings.warn(\"Unable to load geopandas/shapely; ocean shape mask\"\n"
     ]
    }
   ],
   "source": [
    "from marc_analysis.analysis import global_avg\n",
    "\n",
    "def calc_loading(src):\n",
    "    field = \"{}_LDG\".format(src)\n",
    "\n",
    "    monthly = global_avg(average_data[field])\n",
    "    instant = global_avg(instant_data[field]\n",
    "                             .isel(time=slice(5,None))\n",
    "#                              .resample('MS', dim='time', how='mean')\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame({'instant': instant.to_series(),\n",
    "                         'monthly': monthly.to_series()})\n",
    "\n",
    "flds = ['BC', 'MBS', 'OC', 'SUL', 'pSUL']\n",
    "\n",
    "nrow, ncol = 3, 2\n",
    "aspect, size = 16./10., 3.\n",
    "figsize = (ncol * size * aspect, nrow * size)\n",
    "\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=figsize, sharex=True)\n",
    "for i, (ax, fld) in enumerate(zip(list(axes.flat), flds)):\n",
    "    print(fld)\n",
    "    plot_kws = dict(legend=False)\n",
    "    if i == 0:\n",
    "        plot_kws['legend'] = True\n",
    "\n",
    "    loading = calc_loading(fld)\n",
    "    loading.plot(ax=ax, **plot_kws)\n",
    "    ax.set_title(fld + \"_LDG [kg/m^2]\", loc='left')\n",
    "\n",
    "sns.despine(fig)\n",
    "plt.tight_layout()\n",
    "\n",
    "import os\n",
    "plt.savefig(\"figs/validate_ldg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking anything after the first few timesteps should be just fine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
